{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from tqdm import tqdm\n",
    "\n",
    "from agent import Agent\n",
    "from levers import Levers\n",
    "from memory import Memory\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    k=10,\n",
    "    nsteps=1000,\n",
    "    eps=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trial(object):\n",
    "    def __init__(self, args: Namespace):\n",
    "        self.args = args\n",
    "        self.levers = Levers(k=args.k)\n",
    "        self.agent = Agent(k=args.k)\n",
    "\n",
    "    # run the trial and return average rewards\n",
    "    def run(self) -> pd.Series:\n",
    "        for step in range(self.args.nsteps):\n",
    "            lever = self.agent.select_action(eps=self.args.eps)\n",
    "            reward = self.levers.pull(lever)\n",
    "            self.agent.memory.received_rewards.append(reward)\n",
    "            self.agent.memory.update_estimates(lever, reward)\n",
    "\n",
    "        received_rewards = pd.Series(self.agent.memory.received_rewards)\n",
    "        return received_rewards.cumsum() / (received_rewards.index + 1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epss = [0.0, 0.01, 0.1]\n",
    "trial_results = {eps: list() for eps in epss}\n",
    "\n",
    "ntrials = 2000\n",
    "\n",
    "for eps in epss:\n",
    "    args.eps = eps\n",
    "    print(f\"Now training with eps = {eps}\")\n",
    "    for _ in tqdm(range(ntrials)):\n",
    "        trial = Trial(args)\n",
    "        trial_result = trial.run()\n",
    "        trial_results[eps].append(trial_result)\n",
    "        del trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_rewards = dict()\n",
    "\n",
    "for eps in epss:\n",
    "    averaged_rewards[eps] = pd.concat(objs=trial_results[eps], axis=1).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_rewards.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(averaged_rewards[0.0])\n",
    "plt.plot(averaged_rewards[0.01])\n",
    "plt.plot(averaged_rewards[0.1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda-11.3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35b66dd0c8f752918e1728d86abaa8fb004a7dee1d90779ea4d0023d852f9fe7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
